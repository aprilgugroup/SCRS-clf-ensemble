---
title: Strain-level SCRS classification analysis (26 classes)
author: Research notes
date: October 2018
output:
  html_document:
    toc: true
    toc_depth: 3
---


# Data overview

## Preprocess

Raw data acquired is in Horiba format (encoded, maybe compressed/encrypted).
Data transformed by Dongqi using Horiba's LabSpec 6.
In three datasets:

* Exponential phase: 25 strains, 1440 samples
* Platform P1: 26 strains, 1392 samples
* Platform P2: 26 strains, 1407 samples
* TOTAL: 26 strains, 4239 samples

<font color="#FF0000"><b>!NOTE!</b></font> Non-essential changes made to the dataset:

* EXPONENT1-50/<font color="#FF0000">18-585/18-585</font> (containing redundant files as EXPONENT1-50/<font color="#FF0000">18-585</font>) is omitted
* PLATFORM1-50/18<font color="#FF0000">\_</font>3 renamed to PLATFORM1-50/18<font color="#FF0000">-</font>3

Check dimensionality:

```bash
$ find -name '*.txt' -exec wc -l {} \; | cut -f 1 -d ' ' | sort | uniq
```

All files have 1024 dimensions. Now check the number of samples:

```bash
$ ./script/hist_labels.py
```

![Number of samples in each dataset](./image/hist_labels.png)

The exponential phase has no strain "18-4".
Note all three datasets have roughly balanced classes.
But each class is relatively small due to the number of classes.
The SCRS were normalized by "l2", mean scaled by the root square sum.

Now it is good to explore the entire shape of data before doing analysis:
```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	python3 ./script/data_pca.py \
		--data ./data/$file".normalized_l2.data.tsv" \
		--meta ./data/$file".normalized_l2.meta.tsv"
done
```

![PCA of exponential phase](./image/EXPONENT1-50.normalized_l2.data.tsv.pca.png)

![PCA of platform phase 1](./image/PLATFORM1-50.normalized_l2.data.tsv.pca.png)

![PCA of platform phase 2](./image/PLATFORM2-50.normalized_l2.data.tsv.pca.png)


# Exploratory 1

## Gaussian Naive Bayes (GNB)

Try GNB `(sklearn.naive_bayes.GaussianNB)`.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	for pca in {none,20,26,40}; do
		python3 ./script/t1_methods.py \
			--data ./data/$file".normalized_l2.data.tsv" \
			--meta ./data/$file".normalized_l2.meta.tsv" \
			--model gnb --pca $pca
	done
done
```

### GNB: w/o dimension reduction

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.gnb.pca_none.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.gnb.pca_none.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.gnb.pca_none.10_fold.png)

### GNB: dimension reduction: PCA (20)

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.gnb.pca_20.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.gnb.pca_20.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.gnb.pca_20.10_fold.png)

### GNB: dimension reduction: PCA (26)

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.gnb.pca_26.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.gnb.pca_26.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.gnb.pca_26.10_fold.png)


## Logistic Regression (LR)

Try LR `(sklearn.linear_model.LogsticRegression)`.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	for pca in {none,20,26,40}; do
		python3 ./script/t1_methods.py \
			--data ./data/$file".normalized_l2.data.tsv" \
			--meta ./data/$file".normalized_l2.meta.tsv" \
			--model lr --pca $pca
	done
done
```

### LR: w/o dimension reduction

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lr.pca_none.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lr.pca_none.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lr.pca_none.10_fold.png)

### LR: dimension reduction: PCA (20)

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lr.pca_20.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lr.pca_20.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lr.pca_20.10_fold.png)

### LR: dimension reduction: PCA (26)

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lr.pca_26.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lr.pca_26.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lr.pca_26.10_fold.png)


## Linear Discriminant Analysis (LDA)

Try LDA `(sklearn.discriminant_analysis.LinearDiscriminantAnalysis)` as classifier.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	for pca in {none,20,26,40}; do
		python3 ./script/t1_methods.py \
			--data ./data/$file".normalized_l2.data.tsv" \
			--meta ./data/$file".normalized_l2.meta.tsv" \
			--model lda --pca $pca
	done
done
```

### LDA: w/o dimension reduction

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lda.pca_none.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lda.pca_none.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lda.pca_none.10_fold.png)

### LDA: dimension reduction: PCA (20)

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lda.pca_20.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lda.pca_20.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lda.pca_20.10_fold.png)

### LDA: dimension reduction: PCA (26)

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lda.pca_26.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lda.pca_26.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lda.pca_26.10_fold.png)


# Exploratory 2

## Linear Support Vector Machine (SVM)

Try SVM `(sklearn.svm.LinearSVM)`.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	python3 ./script/t1_methods.py \
		--data ./data/$file".normalized_l2.data.tsv" \
		--meta ./data/$file".normalized_l2.meta.tsv" \
		--model svm_lin
done
```

### SVM: w/o dimension reduction

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.svm_lin.pca_none.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.svm_lin.pca_none.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.svm_lin.pca_none.10_fold.png)


## Kernel Support Vector Machine (SVM + RBF kernel)

Try SVM `(sklearn.svm.SVM(kernel = "rbf", gamma = <median Euclidean training set>))`.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	python3 ./script/t1_methods.py \
		--data ./data/$file".normalized_l2.data.tsv" \
		--meta ./data/$file".normalized_l2.meta.tsv" \
		--model svm_rbf
done
```

### SVM: w/o dimension reduction

#### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.svm_rbf.pca_none.10_fold.png)

#### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.svm_rbf.pca_none.10_fold.png)

#### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.svm_rbf.pca_none.10_fold.png)


<!-- # HSIC Dimenstion Reduction (26)

As known ground truth, use `--num-clusters=26 --reduce-dims-to=26`.


```bash
for model in {gnb,lr,lda,svm_lin,svm_rbf}; do
	for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
		python3 ./script/t1_methods.py \
			--data ./data/$file".normalized_l2.data.tsv.lsdr.tsv" \
			--meta ./data/$file".normalized_l2.meta.tsv" \
			--model $model
	done
done
```

## Gaussian Naive Bayes (GNB)

### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lsdr.tsv.gnb.pca_none.10_fold.png)

### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lsdr.tsv.gnb.pca_none.10_fold.png)

### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lsdr.tsv.gnb.pca_none.10_fold.png)


## Logistic Regression (LR)

### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lsdr.tsv.lr.pca_none.10_fold.png)

### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lsdr.tsv.lr.pca_none.10_fold.png)

### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lsdr.tsv.lr.pca_none.10_fold.png)


## Linear Discriminant Analysis (LDA)

### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lsdr.tsv.lda.pca_none.10_fold.png)

### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lsdr.tsv.lda.pca_none.10_fold.png)

### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lsdr.tsv.lda.pca_none.10_fold.png)


## Linear Support Vector Machine (SVM)

### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lsdr.tsv.svm_lin.pca_none.10_fold.png)

### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lsdr.tsv.svm_lin.pca_none.10_fold.png)

### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lsdr.tsv.svm_lin.pca_none.10_fold.png)


## Kernel Support Vector Machine (SVM + RBF kernel)

### Exponential phase

![](./image/EXPONENT1-50.normalized_l2.data.tsv.lsdr.tsv.svm_rbf.pca_none.10_fold.png)

### Platform phase 1

![](./image/PLATFORM1-50.normalized_l2.data.tsv.lsdr.tsv.svm_rbf.pca_none.10_fold.png)

### Platform phase 2

![](./image/PLATFORM2-50.normalized_l2.data.tsv.lsdr.tsv.svm_rbf.pca_none.10_fold.png) -->




# NOTES

## 2018-12-28

* In cross-validataion, dimension reduction on full dataset then split, or split first then do on training set only? <b>A: should do only on training sets (i.e. consider as a part of training).</b>

