---
title: Clustering analysis of SCRS 26 strains
author: Guangyu Li
date: October 2018
output:
  html_document:
    toc: true
    toc_depth: 3
---


# Data overview

## Preprocess

Raw data acquired is in Horiba format (encoded, maybe compressed/encrypted).
Data transformed by Dongqi using Horiba's LabSpec 6.
In three datasets:

* Exponential phase: 25 strains, 1440 samples
* Platform P1: 26 strains, 1392 samples
* Platform P2: 26 strains, 1407 samples
* TOTAL: 26 strains, 4239 samples

<font color="#FF0000"><b>!NOTE!</b></font> Non-essential changes made to the dataset:

* EXPONENT1-50/<font color="#FF0000">18-585/18-585</font> (containing redundant files as EXPONENT1-50/<font color="#FF0000">18-585</font>) is omitted
* PLATFORM1-50/18<font color="#FF0000">\_</font>3 renamed to PLATFORM1-50/18<font color="#FF0000">-</font>3

Check dimensionality:

```bash
$ find -name '*.txt' -exec wc -l {} \; | cut -f 1 -d ' ' | sort | uniq
```

All files have 1024 dimensions. Now check the number of samples:

```bash
$ ./script/hist_labels.py
```

![Number of samples in each dataset](./image/hist_labels.png)

The exponential phase has no strain "18-4".
Note all three datasets have roughly balanced classes.
But each class is relatively small due to the number of classes.
The SCRS were normalized by "l2", mean scaled by the root square sum.

Now it is good to explore the entire shape of data before doing analysis:
```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	python3 ./script/data_pca.py \
		--data ./data/$file".normalized_l2.data.tsv" \
		--meta ./data/$file".normalized_l2.meta.tsv"
done
```

![PCA of exponential phase](./image/EXPONENT1-50.normalized_l2.data.tsv.pac.png)

![PCA of platform phase 1](./image/PLATFORM1-50.normalized_l2.data.tsv.pac.png)

![PCA of platform phase 2](./image/PLATFORM2-50.normalized_l2.data.tsv.pac.png)


# Exploratory 1

## Gaussian Naive Bayes (GNB)

Try GNB `(sklearn.naive_bayes.GaussianNB)`.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	for pca in {none,20,26,40}; do
		python3 ./script/t1_methods.py \
			--data ./data/$file".normalized_l2.data.tsv" \
			--meta ./data/$file".normalized_l2.meta.tsv" \
			--model gnb --pca $pca
	done
done
# similar to other two datasets
```

### Without dimension reduction

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.gnb.pca_none.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.gnb.pca_none.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.gnb.pca_none.10_fold.png)

### Dimension reduction: PCA (20)

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.gnb.pca_20.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.gnb.pca_20.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.gnb.pca_20.10_fold.png)

### Dimension reduction: PCA (26)

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.gnb.pca_26.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.gnb.pca_26.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.gnb.pca_26.10_fold.png)


## Logistic Regression (LR)

Try LR `(sklearn.linear_model.LogsticRegression)`.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	for pca in {none,20,26,40}; do
		python3 ./script/t1_methods.py \
			--data ./data/$file".normalized_l2.data.tsv" \
			--meta ./data/$file".normalized_l2.meta.tsv" \
			--model lr --pca $pca
	done
done
# similar to other two datasets
```

### Without dimension reduction

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.lr.pca_none.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.lr.pca_none.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.lr.pca_none.10_fold.png)

### Dimension reduction: PCA (20)

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.lr.pca_20.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.lr.pca_20.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.lr.pca_20.10_fold.png)

### Dimension reduction: PCA (26)

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.lr.pca_26.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.lr.pca_26.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.lr.pca_26.10_fold.png)


## Linear Discriminant Analysis (LDA)

Try LDA `(sklearn.discriminant_analysis.LinearDiscriminantAnalysis)` as classifier.
10-fold cross-validation, each class evenly splited into each sets.

```bash
for file in {EXPONENT1-50,PLATFORM1-50,PLATFORM2-50}; do
	for pca in {none,20,26,40}; do
		python3 ./script/t1_methods.py \
			--data ./data/$file".normalized_l2.data.tsv" \
			--meta ./data/$file".normalized_l2.meta.tsv" \
			--model lda --pca $pca
	done
done
# similar to other two datasets
```

### Without dimension reduction

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.lda.pca_none.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.lda.pca_none.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.lda.pca_none.10_fold.png)

### Dimension reduction: PCA (20)

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.lda.pca_20.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.lda.pca_20.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.lda.pca_20.10_fold.png)

### Dimension reduction: PCA (26)

#### Exponential phase

![GNB on 10-fold CV](./image/EXPONENT1-50.normalized_l2.data.tsv.lda.pca_26.10_fold.png)

#### Platform phase 1

![GNB on 10-fold CV](./image/PLATFORM1-50.normalized_l2.data.tsv.lda.pca_26.10_fold.png)

#### Platform phase 2

![GNB on 10-fold CV](./image/PLATFORM2-50.normalized_l2.data.tsv.lda.pca_26.10_fold.png)

